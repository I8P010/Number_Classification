{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "244b139a-6af9-49ee-be9c-476dd708a3e9",
      "metadata": {
        "id": "244b139a-6af9-49ee-be9c-476dd708a3e9",
        "outputId": "5a73462e-f925-449c-d5db-44e06050e56d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: GPUtil in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "torch version: 2.6.0+cu124 | device: cuda:0\n",
            "GPUtil version: 1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install GPUtil\n",
        "\n",
        "import torch\n",
        "import GPUtil\n",
        "\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "print(f'torch version: {torch.__version__} | device: {device}')\n",
        "print(f'GPUtil version: {GPUtil.__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gpus = GPUtil.getGPUs()\n",
        "if gpus:\n",
        "    for i, gpu in enumerate(gpus):\n",
        "        print(f\"GPU {i + 1}: {gpu.name}\")\n",
        "        print(f\"  Vendor: NVIDIA\")\n",
        "        print(f\"  Driver: {gpu.driver}\")\n",
        "        print(f\"  GPU Load: {gpu.load * 100:.1f}%\")\n",
        "        print(f\"  Free Memory: {gpu.memoryFree}MB\")\n",
        "        print(f\"  Used Memory: {gpu.memoryUsed}MB\")\n",
        "        print(f\"  Total Memory: {gpu.memoryTotal}MB\")\n",
        "        print(f\"  Temperature: {gpu.temperature}°C\")\n",
        "else:\n",
        "  print('no gpu')"
      ],
      "metadata": {
        "id": "wryXDScL3ofD",
        "outputId": "5b78a4cd-7666-4c2b-c57c-9571afbdecf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wryXDScL3ofD",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 1: Tesla T4\n",
            "  Vendor: NVIDIA\n",
            "  Driver: 550.54.15\n",
            "  GPU Load: 0.0%\n",
            "  Free Memory: 15092.0MB\n",
            "  Used Memory: 2.0MB\n",
            "  Total Memory: 15360.0MB\n",
            "  Temperature: 41.0°C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "701fac53-7cf9-40c3-aa00-8beade52f856",
      "metadata": {
        "id": "701fac53-7cf9-40c3-aa00-8beade52f856"
      },
      "outputs": [],
      "source": [
        "class IncorrectKernelSizeException(Exception):\n",
        "    def __init__(self, kernel_size):\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Incorrect kernel size: {self.kernel_size}. It must be odd.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4c3c4e25-ea8a-4878-bf21-f506d612d396",
      "metadata": {
        "id": "4c3c4e25-ea8a-4878-bf21-f506d612d396"
      },
      "outputs": [],
      "source": [
        "class ResidualConvBlock(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_c,\n",
        "        out_c,\n",
        "        kernel_size: int = 3,\n",
        "        activation = torch.nn.ReLU,\n",
        "        *, # Только именованные параметры\n",
        "        use_bias = True\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "        self.activation = activation()\n",
        "\n",
        "        if kernel_size % 2 != 0:\n",
        "            padding_size = (kernel_size - 1) // 2\n",
        "        else:\n",
        "            raise IncorrectKernelSizeException(kernel_size)\n",
        "\n",
        "        # print(in_c, out_c, kernel_size, padding_size, '\\n---------------------------------------')\n",
        "\n",
        "        self.conv = torch.nn.Conv2d(\n",
        "            in_channels = in_c,\n",
        "            out_channels = out_c,\n",
        "            kernel_size = kernel_size,\n",
        "            padding = padding_size,\n",
        "            padding_mode = 'zeros',\n",
        "            bias = use_bias\n",
        "        )\n",
        "\n",
        "        if in_c == out_c:\n",
        "            self.in_layer = torch.nn.Identity()\n",
        "        else:\n",
        "            self.in_layer = torch.nn.Conv2d(\n",
        "                in_channels = in_c,\n",
        "                out_channels = out_c,\n",
        "                kernel_size = 1\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.activation(self.in_layer(x) + self.conv(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "421fc0d6-815a-490a-9622-72194d63fcd6",
      "metadata": {
        "id": "421fc0d6-815a-490a-9622-72194d63fcd6"
      },
      "outputs": [],
      "source": [
        "class GlobalMaxPooling(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.max(-1).values.max(-1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "94e29ba4",
      "metadata": {
        "id": "94e29ba4"
      },
      "outputs": [],
      "source": [
        "class GlobalAvgPolling(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    #TODO: to make this AvgPooling module\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "686d20b2-40cd-425c-91ef-b39c4a459eb6",
      "metadata": {
        "id": "686d20b2-40cd-425c-91ef-b39c4a459eb6"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "class ConvNetwork(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        classes_num: int, # Количество выходных значений. Количество клаасов для предсказания\n",
        "        conv_params: list[tuple], # Список кортежей следующего вида: (кол-во блоков между пулингами, число каналов на входе/выходе блоков, размер ядра, функция активации)\n",
        "        linear_params: list[tuple] = [], # Список кортежей следующего вида: (кол-во нейронов на i-ом слое, функция активации на i-ом слое). Начинаем с 2-ого слоя, заканчиваем предпоследним слоем (отсчёт с 1). (P.S. Кол-во нейронов и функция активации на входном и выхдном слоях известны и так)\n",
        "        use_Softmax: bool = False\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        conv_layers = []\n",
        "        linear_layers = []\n",
        "\n",
        "        # Собираем свёрточную часть\n",
        "\n",
        "        in_channels = 1\n",
        "        for group_num, (blocks_amount, channels_num, kernel_size, activation) in enumerate(conv_params):\n",
        "            if group_num == len(conv_params) - 1:\n",
        "                linear_in = channels_num # Рассчитываем входной вектор линейного слоя\n",
        "\n",
        "            for block_num in range(blocks_amount):\n",
        "\n",
        "                if block_num != 0:\n",
        "                    in_channels = channels_num\n",
        "\n",
        "                conv_layers.append(\n",
        "                    (\n",
        "                        f'ResidualBlock {group_num} {block_num}',\n",
        "                        ResidualConvBlock(\n",
        "                            in_c = in_channels,\n",
        "                            out_c = channels_num,\n",
        "                            kernel_size = kernel_size,\n",
        "                            activation = activation\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            if group_num < len(conv_params) - 1:\n",
        "                conv_layers.append(\n",
        "                    (\n",
        "                        f'Pooling {group_num}',\n",
        "                        torch.nn.AvgPool2d(2)\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        # Собираем Global Max Pooling\n",
        "\n",
        "        gm_pooling = [('Global Max Pooling', GlobalMaxPooling())]\n",
        "\n",
        "        # Собираем линейную часть\n",
        "\n",
        "        if len(linear_params) == 0:\n",
        "            linear_layers.append(('Linear 0', torch.nn.Linear(linear_in, classes_num)))\n",
        "            linear_layers.append(('Activation 0', torch.nn.Softmax(-1) if use_Softmax else torch.nn.LogSoftmax(-1)))\n",
        "\n",
        "        else:\n",
        "            (first_out, activation) = linear_params[0]\n",
        "            linear_layers.append(('Linear 0', torch.nn.Linear(linear_in, first_out)))\n",
        "            linear_layers.append(('Activation 0', activation()))\n",
        "\n",
        "            for i in range(len(linear_params)):\n",
        "                (in_size, _) = linear_params[i - 1]\n",
        "                (out_size, activation) = linear_params[i]\n",
        "                linear_layers.append((f'Linear {i + 1}', torch.nn.Linear(in_size, out_size)))\n",
        "                linear_layers.append((f'Activation {i + 1}', activation()))\n",
        "\n",
        "            (last_in, _) = linear_params[-1]\n",
        "            linear_layers.append((f'Linear {len(linear_params)}', torch.nn.Linear(last_in, classes_num)))\n",
        "            linear_layers.append((f'Activation {len(linear_params)}', torch.nn.Softmax(-1) if use_Softmax else torch.nn.LogSoftmax(-1)))\n",
        "\n",
        "        #\n",
        "\n",
        "        all_layers = conv_layers + gm_pooling + linear_layers\n",
        "        self.final_model = torch.nn.Sequential(OrderedDict(all_layers))\n",
        "\n",
        "    def forward(self, x): # bs x h x w\n",
        "        x = x.unsqueeze(1) # bs x c x h x w\n",
        "        return self.final_model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "da6f948b",
      "metadata": {
        "id": "da6f948b"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "download_dir = '.\\dataset'\n",
        "\n",
        "train_data = datasets.MNIST(root=download_dir, download=True, train=True)\n",
        "val_data = datasets.MNIST(root=download_dir, download=True, train=False)\n",
        "\n",
        "x_train = train_data.data.to(device=device)\n",
        "y_train = train_data.targets.to(device=device)\n",
        "\n",
        "x_val = val_data.data.to(device=device)\n",
        "y_val = val_data.targets.to(device=device)\n",
        "\n",
        "x_train = x_train / 255.\n",
        "x_val = x_val / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7174f6c4",
      "metadata": {
        "id": "7174f6c4",
        "outputId": "20267209-ebb8-45c2-92dc-c27b6035f370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNetwork(\n",
            "  (final_model): Sequential(\n",
            "    (ResidualBlock 0 0): ResidualConvBlock(\n",
            "      (activation): ReLU()\n",
            "      (conv): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (in_layer): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (ResidualBlock 0 1): ResidualConvBlock(\n",
            "      (activation): ReLU()\n",
            "      (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (in_layer): Identity()\n",
            "    )\n",
            "    (ResidualBlock 0 2): ResidualConvBlock(\n",
            "      (activation): ReLU()\n",
            "      (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (in_layer): Identity()\n",
            "    )\n",
            "    (Pooling 0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (ResidualBlock 1 0): ResidualConvBlock(\n",
            "      (activation): ReLU()\n",
            "      (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (in_layer): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (ResidualBlock 1 1): ResidualConvBlock(\n",
            "      (activation): ReLU()\n",
            "      (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (in_layer): Identity()\n",
            "    )\n",
            "    (ResidualBlock 1 2): ResidualConvBlock(\n",
            "      (activation): ReLU()\n",
            "      (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (in_layer): Identity()\n",
            "    )\n",
            "    (Pooling 1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (ResidualBlock 2 0): ResidualConvBlock(\n",
            "      (activation): ReLU()\n",
            "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (in_layer): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (ResidualBlock 2 1): ResidualConvBlock(\n",
            "      (activation): ReLU()\n",
            "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (in_layer): Identity()\n",
            "    )\n",
            "    (ResidualBlock 2 2): ResidualConvBlock(\n",
            "      (activation): ReLU()\n",
            "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (in_layer): Identity()\n",
            "    )\n",
            "    (Global Max Pooling): GlobalMaxPooling()\n",
            "    (Linear 0): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (Activation 0): ReLU()\n",
            "    (Linear 1): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (Activation 1): ReLU()\n",
            "    (Linear 2): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (Activation 2): ReLU()\n",
            "    (Linear 3): Linear(in_features=32, out_features=10, bias=True)\n",
            "    (Activation 3): LogSoftmax(dim=-1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = ConvNetwork(\n",
        "    classes_num=10,\n",
        "    conv_params=[(3, 8, 3, torch.nn.ReLU), (3, 16, 3, torch.nn.ReLU), (3, 32, 3, torch.nn.ReLU)],\n",
        "    linear_params=[(32, torch.nn.ReLU), (32, torch.nn.ReLU), (32, torch.nn.ReLU)]\n",
        ").to(device=device, dtype=x_train.dtype)\n",
        "\n",
        "print(model)\n",
        "# in out kenel padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2f7841d0",
      "metadata": {
        "id": "2f7841d0",
        "outputId": "64f438a1-607d-4637-fa50-cfa811c4bb8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100. loss: 2.307145833969116\n",
            "200. loss: 2.3069260120391846\n",
            "300. loss: 2.3024818897247314\n",
            "400. loss: 2.302112579345703\n",
            "500. loss: 2.3038246631622314\n",
            "600. loss: 2.302116632461548\n",
            "700. loss: 2.3029730319976807\n",
            "800. loss: 2.301987409591675\n",
            "900. loss: 2.3005146980285645\n",
            "1000. loss: 2.301605224609375\n",
            "1100. loss: 2.299149990081787\n",
            "1200. loss: 2.3002984523773193\n",
            "1300. loss: 2.2992303371429443\n",
            "1400. loss: 2.2975265979766846\n",
            "1500. loss: 2.2972686290740967\n",
            "1600. loss: 2.3009586334228516\n",
            "1700. loss: 2.295868158340454\n",
            "1800. loss: 2.2997405529022217\n",
            "1900. loss: 2.297366142272949\n",
            "2000. loss: 2.2942280769348145\n",
            "2100. loss: 2.2931835651397705\n",
            "2200. loss: 2.300464630126953\n",
            "2300. loss: 2.2928662300109863\n",
            "2400. loss: 2.2954022884368896\n",
            "2500. loss: 2.2924256324768066\n",
            "2600. loss: 2.2942023277282715\n",
            "2700. loss: 2.292008399963379\n",
            "2800. loss: 2.294830799102783\n",
            "2900. loss: 2.2938599586486816\n",
            "3000. loss: 2.2946197986602783\n",
            "3100. loss: 2.2882602214813232\n",
            "3200. loss: 2.2895781993865967\n",
            "3300. loss: 2.2903175354003906\n",
            "3400. loss: 2.2876226902008057\n",
            "3500. loss: 2.2825911045074463\n",
            "3600. loss: 2.281947612762451\n",
            "3700. loss: 2.2796480655670166\n",
            "3800. loss: 2.2779178619384766\n",
            "3900. loss: 2.2720859050750732\n",
            "4000. loss: 2.2709403038024902\n",
            "4100. loss: 2.268566608428955\n",
            "4200. loss: 2.2683513164520264\n",
            "4300. loss: 2.2599539756774902\n",
            "4400. loss: 2.2639925479888916\n",
            "4500. loss: 2.254349708557129\n",
            "4600. loss: 2.249030590057373\n",
            "4700. loss: 2.237748384475708\n",
            "4800. loss: 2.235821008682251\n",
            "4900. loss: 2.223931312561035\n",
            "5000. loss: 2.208743095397949\n",
            "5100. loss: 2.1993918418884277\n",
            "5200. loss: 2.188981771469116\n",
            "5300. loss: 2.1925079822540283\n",
            "5400. loss: 2.1700997352600098\n",
            "5500. loss: 2.166884422302246\n",
            "5600. loss: 2.1430253982543945\n",
            "5700. loss: 2.126722574234009\n",
            "5800. loss: 2.0849802494049072\n",
            "5900. loss: 2.076714038848877\n",
            "6000. loss: 2.0419440269470215\n",
            "6100. loss: 1.982227087020874\n",
            "6200. loss: 1.939926266670227\n",
            "6300. loss: 1.911658763885498\n",
            "6400. loss: 1.9097424745559692\n",
            "6500. loss: 1.8493155241012573\n",
            "6600. loss: 1.8296040296554565\n",
            "6700. loss: 1.816689133644104\n",
            "6800. loss: 1.7755588293075562\n",
            "6900. loss: 1.7400661706924438\n",
            "7000. loss: 1.6928611993789673\n",
            "7100. loss: 1.7150324583053589\n",
            "7200. loss: 1.6904937028884888\n",
            "7300. loss: 1.7596333026885986\n",
            "7400. loss: 1.6492058038711548\n",
            "7500. loss: 1.7340556383132935\n",
            "7600. loss: 1.5062878131866455\n",
            "7700. loss: 1.477569341659546\n",
            "7800. loss: 1.4330538511276245\n",
            "7900. loss: 1.4293010234832764\n",
            "8000. loss: 1.44339120388031\n",
            "8100. loss: 1.3457988500595093\n",
            "8200. loss: 1.3388042449951172\n",
            "8300. loss: 1.3567240238189697\n",
            "8400. loss: 1.3291029930114746\n",
            "8500. loss: 1.3282980918884277\n",
            "8600. loss: 1.3514299392700195\n",
            "8700. loss: 1.4004297256469727\n",
            "8800. loss: 1.262601613998413\n",
            "8900. loss: 1.221154808998108\n",
            "9000. loss: 1.18407142162323\n",
            "9100. loss: 1.1883574724197388\n",
            "9200. loss: 1.1882961988449097\n",
            "9300. loss: 1.1631168127059937\n",
            "9400. loss: 1.1225556135177612\n",
            "9500. loss: 1.1307402849197388\n",
            "9600. loss: 1.1358157396316528\n",
            "9700. loss: 1.1236920356750488\n",
            "9800. loss: 1.1258670091629028\n",
            "9900. loss: 1.0831942558288574\n",
            "10000. loss: 1.0807726383209229\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.SGD(\n",
        "    params=model.parameters(),\n",
        "    lr=.01\n",
        ")\n",
        "\n",
        "EPOCHS_NUM = 10000\n",
        "BATCH_SIZE = 1000\n",
        "loss_fn = torch.nn.NLLLoss()\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5)\n",
        "\n",
        "for epoch in range(1, EPOCHS_NUM + 1):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # TODO: Доделать обучение\n",
        "\n",
        "    batch_pos = torch.randint(low=0, high=y_train.shape[0], size=[BATCH_SIZE])\n",
        "    pred = model(x_train[batch_pos]).to(device=device)\n",
        "    loss = loss_fn(pred, y_train[batch_pos]).to(device=device)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'{epoch}. loss: {loss.item()}')\n",
        "\n",
        "    if epoch % 1250 == 0:\n",
        "        scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e79f786b",
      "metadata": {
        "id": "e79f786b",
        "outputId": "3a592292-2960-48f0-bf6c-3305843dc979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "tensor([[[1, 2, 3]],\n",
            "\n",
            "        [[4, 5, 6]]])\n",
            "torch.Size([2, 1, 3])\n",
            "tensor([[[[1, 2, 3]]],\n",
            "\n",
            "\n",
            "        [[[4, 5, 6]]]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "print(x.shape)\n",
        "x.unsqueeze_(1)\n",
        "print(x)\n",
        "print(x.shape)\n",
        "x = x[:, None, :]\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8464b7bd",
      "metadata": {
        "id": "8464b7bd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}